#!/bin/bash

# Script to run evaluation using precalculated statistics.
# This script evaluates generated images against original images using
# precomputed FID statistics, segmentation maps, and LPIPS features.
#
# Two-step process:
# 1. Create manifest matching generated images to originals (handles _fake suffix, nested dirs)
# 2. Run evaluation using the manifest

# Directories
# Generated: The generated/translated images to evaluate
GENERATED_ROOT_DIR="/scratch/aaa_exchange/AWARE/GENERATED_IMAGES"

if [ "$1" == "--regenerate-manifest" ]; then
    MODEL="${2:-CUT}"
else
    MODEL="${1:-CUT}"
fi

GENERATED_DIR="${GENERATED_ROOT_DIR}/${MODEL}"

# Original: The original source images (for paired metrics like SSIM, LPIPS, PSNR)
ORIGINAL_DIR="/scratch/aaa_exchange/AWARE/FINAL_SPLITS/train/images"

# Target: The target domain images (only needed if stats aren't precomputed)
TARGET_DIR="/scratch/aaa_exchange/AWARE/AWACS/train"

# Statistics directory (contains precomputed FID stats, segmentation, LPIPS features)
STATS_DIR="/scratch/aaa_exchange/AWARE/STATS/"

# Manifest file (created by preprocessing step)
MANIFEST_FILE="manifests/${MODEL}/manifest.csv"

# Output file for evaluation results
OUTPUT_FILE="${MODEL}_evaluation_results.json"

# Cache directory for models
CACHE_DIR="/scratch/$USER/models"

echo "========================================="
echo "Evaluation Pipeline"
echo "========================================="
echo "Generated Dir: $GENERATED_DIR"
echo "Original Dir: $ORIGINAL_DIR"
echo "Target Dir: $TARGET_DIR"
echo "Stats Dir: $STATS_DIR"
echo "Manifest: $MANIFEST_FILE"
echo "Output: $OUTPUT_FILE"
echo "Cache Dir: $CACHE_DIR"
echo ""

source venv/bin/activate

# Step 1: Create manifest (if not exists or force regenerate)
if [ ! -f "$MANIFEST_FILE" ] || [ "$1" == "--regenerate-manifest" ]; then
    echo "Step 1: Creating evaluation manifest..."
    python3 helper/prepare_evaluation_manifest.py \
        --generated "$GENERATED_DIR" \
        --original "$ORIGINAL_DIR" \
        --target "$TARGET_DIR" \
        -o "$MANIFEST_FILE" \
        --verbose
    
    if [ $? -ne 0 ]; then
        echo "Error: Manifest creation failed"
        exit 1
    fi
    echo ""
else
    echo "Step 1: Using existing manifest: $MANIFEST_FILE"
    echo ""
fi

# Step 2: Run evaluation using the manifest
echo "Step 2: Running evaluation..."
python3 evaluate_generation.py \
    --generated "$GENERATED_DIR" \
    --original "$ORIGINAL_DIR" \
    --target "$TARGET_DIR" \
    --stats-dir "$STATS_DIR" \
    --pairs csv \
    --manifest "$MANIFEST_FILE" \
    --metrics fid ssim lpips \
    --semantic-consistency \
    --per-domain \
    --device auto \
    --cache-dir "$CACHE_DIR" \
    --batch-size 64 \
    --semantic-batch-size 16 \
    --output "$MODEL" \
    --verbose

echo ""
echo "========================================="
echo "Evaluation complete. Results saved to $OUTPUT_FILE"
echo "========================================="
